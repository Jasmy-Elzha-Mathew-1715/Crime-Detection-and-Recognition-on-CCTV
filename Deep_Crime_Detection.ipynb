{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Crime Detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jasmy-Elzha-Mathew-1715/Crime-Detection-and-Recognition-on-CCTV/blob/main/Deep_Crime_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSTaLQB9Hl4f"
      },
      "source": [
        "Step 1 : Connecting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9rM4wpzHWjk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtW9RrxCH3KX"
      },
      "source": [
        "Step 2 : Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUSnX1ayH7rK"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIn2-wo6IB7h"
      },
      "source": [
        "2.1 : Setting Dimensions of Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geffu067IHEh"
      },
      "source": [
        "frames = 15\n",
        "Width = 256\n",
        "Height = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TRi2vuQIMoD"
      },
      "source": [
        "2.2 : Loading Video Names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "navDAT_eIeiX"
      },
      "source": [
        "def load_video_names(path):\n",
        "  videos = [] \n",
        "  labels = [] \n",
        "  for category in os.listdir(path): \n",
        "    if os.path.isdir(category): \n",
        "      for video in os.listdir(path+\"/\"+category): \n",
        "        videos.append(path+\"/\"+category+\"/\"+video) \n",
        "        labels.append(category)\n",
        "  return np.array(videos), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhKFpEOuInZi"
      },
      "source": [
        "2.3 : Conversion of Frame Pixel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7n2TYQIvAm"
      },
      "source": [
        "def preprocess(frame):\n",
        "  frame = cv2.resize(frame, (Width, Height)) \n",
        "  frame = frame-127.5\n",
        "  frame = frame/127.5\n",
        "  return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnl_rcaJI5Jt"
      },
      "source": [
        "2.4 : Loading Videos from Path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0kNmjLWJAbu"
      },
      "source": [
        "def load_video(video_path):\n",
        "  video_frames = [] \n",
        "  cap = cv2.VideoCapture(video_path) \n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "      video_frames.append(preprocess(frame)) \n",
        "    else:\n",
        "      break\n",
        "  cap.release()\n",
        "  video_frames = select_frames(video_frames) \n",
        "  if len(video_frames) != frames: \n",
        "    print('short_video ', video_path, len(video_frames))\n",
        "    return 0, False\n",
        "\n",
        "  return np.array(video_frames), True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y28GwIEJQTq"
      },
      "source": [
        "2.5 : Choosing Desired No. of Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIKJM2PmJWQn"
      },
      "source": [
        "def select_frames(video_frames):\n",
        "  selected_frames = []\n",
        "  if len(video_frames) > frames:\n",
        "    fn = len(video_frames)//frames \n",
        "    f_num = 0\n",
        "    for f in video_frames:\n",
        "      if len(selected_frames) < frames:\n",
        "        if f_num % fn == 0:\n",
        "          selected_frames.append(f)\n",
        "      f_num += 1\n",
        "  else:\n",
        "    selected_frames = video_frames\n",
        "  return selected_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRcTW0TGJgGk"
      },
      "source": [
        "2.6 : Load Batches of Videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NfVaYQ4JkMJ"
      },
      "source": [
        "def create_dataset(videos, labels, indx):\n",
        "  x = []\n",
        "  y = []\n",
        "  for video, label in zip(videos[indx], labels[indx]):\n",
        "    xi, is_video = load_video(video)\n",
        "\n",
        "    if is_video:\n",
        "      x.append(xi)\n",
        "      y.append(label)\n",
        "\n",
        "  return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ3rhelnJsCc"
      },
      "source": [
        "### Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALdf2kXhJs0z"
      },
      "source": [
        "videos, labels = load_video_names('/content/drive/MyDrive/Crime Detection and Recognition on CCTV/Anomaly_Short')\n",
        "samples = len(videos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZg7EdTuJxFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1578b860-a859-43a3-c7b2-97c6b8823c43"
      },
      "source": [
        "samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InfxpbemJzjO"
      },
      "source": [
        "classes = len(np.unique(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjWkk7uRJ2tX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb775893-0084-4e23-84c2-4c65b196b5f5"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn54WO25J7r6"
      },
      "source": [
        "#print(np.unique(labels, return_counts = True))\n",
        "labels_counts = np.unique(labels, return_counts = True)\n",
        "for l,n in zip(labels_counts[0], labels_counts[1]):\n",
        "  print(l,' > ', n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPr3HHFtJ8ge"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(np.unique(labels))\n",
        "encoded_labels = le.transform(labels)\n",
        "encoded_labels = np.reshape(encoded_labels, (-1,1))\n",
        "np.save(\"classes.npy\", le.classes_)\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(encoded_labels)\n",
        "encoded_labels = encoder.transform(encoded_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbSJu3z8KAFw"
      },
      "source": [
        "print(encoded_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKFVu4xWKDTF"
      },
      "source": [
        "encoded_labels = encoded_labels.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7VwH-QdKGvy"
      },
      "source": [
        "encoded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTwlJ-qkKQis"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfwHBscxctf_"
      },
      "source": [
        "Keras Import for Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBhoLMZvKPnB"
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import TimeDistributed, LSTM\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, LeakyReLU, BatchNormalization\n",
        "from keras.layers import Dense, Flatten, GlobalMaxPooling2D\n",
        "from keras.layers import MaxPooling3D\n",
        "from keras.layers import concatenate\n",
        "\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY29z3HCdW1o"
      },
      "source": [
        "Residual Block for Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6y6dK8uKUxF"
      },
      "source": [
        "def res_block(model, filters):\n",
        "  start_block = model\n",
        "  model = Conv2D(filters=filters, kernel_size = 3, padding='same')(model)\n",
        "  model = BatchNormalization(momentum=0.9)(model)\n",
        "  model = LeakyReLU(0.2)(model)\n",
        "  return concatenate([start_block, model])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zbdHPy6ddqj"
      },
      "source": [
        "Deep Crime Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRKErVW6dU7w"
      },
      "source": [
        "def create_model():\n",
        "    input_layer = Input(shape=(frames, Width, Height,3))\n",
        "    model =  ConvLSTM2D(32,3,padding='same',return_sequences=False)(input_layer)\n",
        "    model = BatchNormalization(momentum=0.9)(model)\n",
        "    model = LeakyReLU(0.2)(model)\n",
        "    filters = 64\n",
        "    for _ in range(6):\n",
        "      model = res_block(model, filters)\n",
        "      try:\n",
        "        model = MaxPooling3D((2,2,2))(model)\n",
        "      except:\n",
        "        model = MaxPooling2D((2,2))(model)\n",
        "      if filters < 512:\n",
        "        filters *= 2\n",
        "    model = Flatten()(model)\n",
        "    model = Dense(classes, activation='softmax')(model)\n",
        "    model = Model(input_layer, model)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbLMPhrqeBwg"
      },
      "source": [
        "classifier = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdDluch1eDFd"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3klIoDleFIa"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwsYVcTQeNCh"
      },
      "source": [
        "Path to save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l1s-HRseI4Q"
      },
      "source": [
        "classifier.save(\"my_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu6aWCIweQOd"
      },
      "source": [
        "try:\n",
        "  classifier.load_weights(classifier)\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6A6f6LeepZy"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx9E0H4qekqI"
      },
      "source": [
        "batch_size = 4\n",
        "if samples//batch_size < samples/batch_size:\n",
        "  batches = (samples//batch_size)+1\n",
        "else:\n",
        "  batches = samples//batch_size\n",
        "for e in range(100):\n",
        "  index = list(range(samples))\n",
        "  np.random.shuffle(index)\n",
        "  accuracy = 0\n",
        "  for batch in range(batches):\n",
        "    bs = batch*batch_size\n",
        "    be = bs+batch_size\n",
        "    selected_indexes = index[bs:be]\n",
        "    x,y = create_dataset(videos, encoded_labels, selected_indexes)\n",
        "    # print(x.shape)\n",
        "    # print(y.shape)\n",
        "    results = classifier.train_on_batch(x,y)\n",
        "    print('\\r',batch,'/',batches,' : ',results[0],results[1],end='')\n",
        "    accuracy += results[1]\n",
        "    if batch%100 == 0:\n",
        "      classifier.save_weights(\"classifier.h5\")\n",
        "  print('\\r> ',e,', Accuracy = ',accuracy/batches)\n",
        "  classifier.save_weights(\"classifier.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3s-Ia1ge5q9"
      },
      "source": [
        "### Testing Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7naNYaQfgSQ"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1L_8vaDfFbQ"
      },
      "source": [
        "classifier.load_weights('/content/drive/MyDrive/Crime Detection and Recognition on CCTV/Anomaly_Short/classifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61D0gNAVflbB"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"(name)\" with length (length) bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  videos, r = load_video(fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URTw-VzmfqyP"
      },
      "source": [
        "print(videos.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdeGVFB6ftC4"
      },
      "source": [
        "result = classifier.predict( np.array([videos]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSfXFxdLfv3J"
      },
      "source": [
        "import numpy as np\n",
        "np.argmax(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnAG-pW5f0ai"
      },
      "source": [
        "le.inverse_transform([np.argmax(result)])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-dUMfhSny5t"
      },
      "source": [
        "### Evaluating Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MYQ1ajVhlzY"
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import os\n",
        "from tqdm.autonotebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import cv2\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qNTuZzlbnAl"
      },
      "source": [
        "# Loading the Model\n",
        "classifier.load_weights('/content/drive/MyDrive/Crime Detection and Recognition on CCTV/Anomaly_Short/classifier.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybCCnE-T8GzU"
      },
      "source": [
        "os.makedirs('/content/drive/MyDrive/Crime Detection and Recognition on CCTV/Results',exist_ok = True)\n",
        "from torch.autograd import Variable\n",
        "iteration = 0\n",
        "acc_all = list()\n",
        "loss_all = list()\n",
        "    \n",
        "for epoch in range(num_epochs):\n",
        "    print('')\n",
        "    print(f\"--- Epoch {epoch} ---\")\n",
        "    phase1 = dataloaders.keys()\n",
        "    for phase in phase1:\n",
        "        print('')\n",
        "        print(f\"--- Phase {phase} ---\")\n",
        "        epoch_metrics = {\"loss\": [], \"acc\": []}\n",
        "        for batch_i, (X, y) in enumerate(dataloaders[phase]):\n",
        "            #iteration = iteration+1\n",
        "            image_sequences = Variable(X.to(device), requires_grad=True)\n",
        "            labels = Variable(y.to(device), requires_grad=False)\n",
        "            optimizer.zero_grad()\n",
        "            #model.lstm.reset_hidden_state()\n",
        "            predictions = model(image_sequences)\n",
        "            loss = cls_criterion(predictions, labels)\n",
        "            acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_metrics[\"loss\"].append(loss.item())\n",
        "            epoch_metrics[\"acc\"].append(acc)\n",
        "            if(phase=='train'):\n",
        "                lr,mom = onecyc.calc()\n",
        "                update_lr(optimizer, lr)\n",
        "                update_mom(optimizer, mom)\n",
        "            batches_done = epoch * len(dataloaders[phase]) + batch_i\n",
        "            batches_left = num_epochs * len(dataloaders[phase]) - batches_done\n",
        "            sys.stdout.write(\n",
        "                    \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f), Acc: %.2f%% (%.2f%%)]\"\n",
        "                    % (\n",
        "                        epoch,\n",
        "                        num_epochs,\n",
        "                        batch_i,\n",
        "                        len(dataloaders[phase]),\n",
        "                        loss.item(),\n",
        "                        np.mean(epoch_metrics[\"loss\"]),\n",
        "                        acc,\n",
        "                        np.mean(epoch_metrics[\"acc\"]),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                # Empty cache\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "        print('')\n",
        "        print('{} , acc: {}'.format(phase,np.mean(epoch_metrics[\"acc\"])))\n",
        "        torch.save(model.state_dict(),'/content/drive/MyDrive/Crime Detection and Recognition on CCTV/Anomaly_Short/classifier.h5'.format(epoch))\n",
        "        if(phase=='train'):\n",
        "          acc_all.append(np.mean(epoch_metrics[\"acc\"]))\n",
        "          loss_all.append(np.mean(epoch_metrics[\"loss\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH7XMOAjV7DH"
      },
      "source": [
        "def error_plot(loss):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(loss)\n",
        "    plt.title(\"Training loss plot\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "def acc_plot(acc):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(acc)\n",
        "    plt.title(\"Training accuracy plot\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoXZ08iHXbD2"
      },
      "source": [
        "loss_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtVNjFyeWVrd"
      },
      "source": [
        "error_plot(loss_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dybBWSyyWZfY"
      },
      "source": [
        "acc_plot(acc_all)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}